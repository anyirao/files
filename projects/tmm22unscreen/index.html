
<!DOCTYPE html>
<html>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>Unscreen</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- <base href="/"> -->

    <link rel="icon" type="image/png" href="../img/cuhk.ico">

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">
    <link rel="stylesheet" href="css/bootstrap.min.css">
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-110862391-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-110862391-3');
    </script>

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    <script src="js/app.js"></script>
</head>

<body>
    <div class="container" id="main">
        <div class="row">
            <h1 class="col-md-12 text-center">
                A Coarse-to-Fine Framework for Automatic Video Unscreen
                <br>
                <small>
                    IEEE Transactions on Multimedia (TMM) 2022
                </small>
            </h1>
        </div>

        <div class="row">
            <div class="col-md-12 text-center">
                <div style="margin-bottom: 0.7em; margin-top:0.2em" class="authors">
                    <a style="color:#000000;" href="https://anyirao.com/">Anyi Rao<sup>1</sup></a>&nbsp;&nbsp;&nbsp;&nbsp;
                    <a style="color:#000000;" href="https://eveneveno.github.io/lnxu/">Linning Xu<sup>1</sup></a>&nbsp;&nbsp;&nbsp;&nbsp;
                    <a style="color:#000000;" href="https://scholar.google.com.hk/citations?user=bS0_aIUAAAAJ&hl=en">Zhizhong Li<sup>2</sup></a>&nbsp;&nbsp;&nbsp;&nbsp;
                    <a style="color:#000000;" href="http://qqhuang.cn/">Qingqiu Huang<sup>1</sup></a>&nbsp;&nbsp;&nbsp;&nbsp;
                    <a style="color:#000000;" href="https://jeffreykuang.github.io/">Zhanghui Kuang<sup>2</sup></a>&nbsp;&nbsp;&nbsp;&nbsp;
                    <a style="color:#000000;" href="http://www.statfe.com/">Wayne Zhang<sup>2</sup></a>&nbsp;&nbsp;&nbsp;&nbsp;
                    <a style="color:#000000;" href="http://dahua.me/">Dahua Lin<sup>1</sup></a>
                </div>

                <div style="margin-bottom: 0.5em;" class="affiliations">
                    <a href="http://mmlab.ie.cuhk.edu.hk/">MMLab, The Chinese University of Hong Kong<sup>1</sup></a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                    <a href="https://www.sensetime.com/en">SenseTime Reseach<sup>2</sup></a>
                </div>

            </div>
        </div>

        <div style="margin-bottom: 0.7em;" class="row">
                <div class="col-md-8 col-md-offset-2 text-center">
                    <ul class="nav nav-pills nav-justified">
                        <li>
                            <a href="">
                            <image src="../img/paper.png" height="50px"><br>
                                <h5><strong>Paper</strong></h5>
                            </a>
                        </li>
                        <li>
                            <a href="https://github.com/AnyiRao/video_unscreen">
                            <image src="../img/github_pad.png" height="50px"><br>
                                <h5><strong>Code</strong></h5>
                            </a>
                        </li>
                        <li>
                            <a href="https://aigc.sensetime.com/">
                            <image src="../img/paperclip.png" height="50px"><br>
                                <h5><strong>Application</strong></h5>
                            </a>
                        </li>
                    </ul>
                </div>
        </div>


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Abstract
                </h3>
                
                <table>
                    <tr>
                    <td width="57%">
                        <image src="img/teaser.jpg" class="img-responsive" alt="overview"><br>    
                    </td>
                    <td width="3%"></td>
                    <td width="40%">
                        Video unscreen, a technique to extract foreground from given videos,
                        has been playing an important role in today's video production pipeline.
                        Existing systems developed for this purpose which mainly rely on video segmentation or video
                        matting,
                        either suffer from quality deficiencies or requiring tedious manual annotations.
                        In this work, we aim to develop a fully automatic video unscreen framework
                        that is able to
                        obtain high-quality foreground extraction without the need of human intervention
                        in a controlled
                        environment. 
                    </td>
                </table>
                    <!-- <p    style="text-align:center;">
                        <image width="60%"  src="img/teaser.jpg" class="img-responsive" alt="overview"><br>    
                    </p> -->

                <p class="text-justify">
                    Inspired by the alpha composition equation, our frame adopts a coarse-to-fine
                        strategy, where the obtained background estimate given an initial mask prediction in turn helps
                        the refinement of the mask. We conducted experiments on two datasets, 1) the Adobe's
                        Synthetic-Composite dataset, and 2) DramaStudio, our newly collected large-scale green screen
                        video matting dataset, exhibiting the controlled environments.
                        The results show that the proposed framework outperforms existing algorithms and commercial
                        software, both quantitatively and qualitatively.
                        We also demonstrate its utility in person replacement in videos,
                        which can further support a variety of video editing applications.
                </p>
            </div>
        </div>
       

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Framework
                </h3>
                <image src="img/pipeline.png" class="img-responsive" alt="overview"><br>
                <p class="text-justify">
                    <strong> The pipeline of the proposed automatic video unscreen system.</strong>
                    The coarse prediction has semantic information but the boundary is not perfect. 
                    The prediction with background information provides fine-grained
                    boundary information but is noisy. 
                    Integrating them produces a better result. 
                    The detailed comparison is shown at the bottom.
                </p>
            </div>
        </div>

        <!-- <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Example Results
                </h3>
                <image src="img/result.png" class="img-responsive" alt="overview"><br>         
                <p class="text-justify">
                    <strong> Qualitative evaluations.</strong>
                    Column 2-3: LayoutVAE and MolVAE fail to capture valid block topology, while our
                    BlockPlanner efficiently generates diverse and valid block layouts with reasonable land use categories. Column 5-6: marker
                    (L) indicates land use level view. Though pixel-based BlockGAN generates sensible structure for large lots, the artifacts such
                    as the fuzzy boundary are significant. In contrast, our vectorized representation captures much more accurate geometry even
                    in small areas. (Dimgray color indicates the unfilled regions.)
                </p>
            </div>
        </div> -->

        <!-- <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    3D Visualization and Animations
                </h3>
                <table>
                    <tr>
                    <td width="33%">
                        <image src="img/supp.png" width=92% class="img-responsive" alt="overview"><br>  
                    </td>
                    <td width="32%">
                        <video id="v11" width="100%" autoplay loop muted controls>
                            <source src="img/block animation.mp4" type="video/mp4" />
                        </video>
                    </td>
                    <td width="32%">
                        <video id="v12" width="100%" autoplay loop muted controls>
                            <source src="img/fun.mp4" type="video/mp4" />
                        </video>
                    </td>
                    
                </tr>
                </table>                
            </div>
        </div> -->
            
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    BibTeX
                </h3>
                <div class="form-group col-md-10 col-md-offset-1">
                    <textarea id="bibtex" class="form-control" readonly>

@article{rao2022coarse,
    title={A Coarse-to-Fine Framework for Automatic Video Unscreen},
    author={Rao, Anyi and Xu, Linning and Li, Zhizhong and Huang, Qingqiu and Kuang, Zhanghui and Zhang, Wayne and Lin, Dahua},
    journal={IEEE Transactions on Multimedia},
    year={2022},
    publisher={IEEE}
}
</textarea>
                </div>
            </div>
        </div>
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Acknowledgements
                </h3>
                <p class="text-justify">
                
                The website template was borrowed from <a href="http://mgharbi.com/">Michaël Gharbi</a>.
                </p>
            </div>
        </div>
    </div>
</body>

	<script type="text/javascript">
        var slideIndex = 1;
        showSlides(slideIndex);

        // Next/previous controls
        function plusSlides(n) {
        showSlides(slideIndex += n);
        }

        // Thumbnail image controls
        function currentSlide(n) {
        showSlides(slideIndex = n);
        }

        function showSlides(n) {
        var i;
        var slides = document.getElementsByClassName("mySlides");
        var dots = document.getElementsByClassName("dot");
        if (n > slides.length) {slideIndex = 1}
        if (n < 1) {slideIndex = slides.length}
        for (i = 0; i < slides.length; i++) {
            slides[i].style.display = "none";
        }
        for (i = 0; i < dots.length; i++) {
            dots[i].className = dots[i].className.replace(" active", "");
        }
        slides[slideIndex-1].style.display = "block";
        dots[slideIndex-1].className += " active";
        }
	</script>




</html>
